1，public class Ma implements OutBack {
    private int nub;

    public void setNub(int nub) {
        this.nub = nub;
    }

    @Override
    public void getBack(double out, int id, long eventId) {
        System.out.println("id==" + id + ",out==" + out + ",nub==" + nub);
    }
}
回调类实现OUTBACK 接口 当检测结果输出的时候 会回调getBack方法
回调第一个参数是输出值 指的是 这个分类的概率 该数值是0-1之间的浮点
第二个参数是 分类的id 判断是训练的哪个分类的ID，
第三个参数是 事件ID,一次判断事件 使用一个ID,让开发者知道是哪次事件的回调判断
2，templeConfig.setDeep(2); 全连接层深度说明
这就像人类大脑的意识深度原理一样，深度学习越深，训练结果越准，但是训练量成几何倍数增加
比如默认深度是2 需要 正负模板各一千+张照片进行训练。识别率70%（只是举个例子，不是真实识别率）
当深度改成3，则需要正负模板各三千+张照片进行训练,识别率 80%
深度4，八千+90%
以此类推，，内存允许的情况下，深度无限 识别率无限接近与百分之百
但是有极限，即超过某个深度，即使再增加深度，识别率反而会下降。需要具体不断尝试找到 合适的深度
注意：若深度提升，训练量没有成倍增长，则准确度反而更低！
3,  templeConfig.setClassificationNub(1);设置有几种分类
如果你只要识别一种分类 例如 一个苹果，那么就写1
如果是 一个苹果 还有香蕉，两种分类 就写2
4,
//设置图像行列比例的行，默认为5 选填
 templeConfig.setRow(5);
//设置图像行列比例的列，默认为3 选填
 templeConfig.setColumn(3);
 图片长宽比，不写默认是row 5, column 3
 这个默认值是按照现在手机竖直的图片的长宽比，目前都是这个数值，横过来的话就是 3：5
 如果不是手机竖直尺寸的图像，且并不确定比例，建议写5：5
 因为算法会对进行图像进行压缩后，进入矩阵，压缩有会有一个默认的矩阵大小，最小压缩到5像素
 所以设置这个，最好要有一个值写5，另外一个自定义，如果不知道就写 5：5
5, Map<Integer, Double> rightTagging = new HashMap<>();//分类标注
        rightTagging.put(1, 1.0);
        rightTagging.put(2, 0.0);
 给训练图像进行标注，健是分类的ID,对应的就是输出结果的ID值，值要么写0要么写1
 1就是 是这种分类，0就是不是这种分类
 例如上面的标注了 该标注是 第一种分类 true,第二种分类FALSE
 将本地图像转化成矩阵
 注意：目前版本该框架，只识别当前图像的灰度图像，对RGB图像进行了降维
 对颜色失去一定的敏感度，所以主要针对物体形状，边缘，若对颜色敏感，请等待后续版本
  Matrix right = picture.getImageMatrixByLocal("/Users/lidapeng/Desktop/myDocment/c/c" + i + ".png");
 还有一个API 是 根据输入流获取图像矩阵
picture.getImageMatrixByIo（inputStream）根据输入流 获取图像矩阵
拿到这个矩阵之后，进行下一步计算
6, templeConfig.initNerveManager(true);//对模板初始化
若第一次学习参数就是true,学习是很慢的,非常考验性能，目前该包没有引入JCUDA(java 显卡GPU运算包)
所以目前使用的是cpu版本,对cpu来说检测单张图片的性能是可以满足的
学习就是学的模型参数，学完了要把模型参数拿出来，下次直接注入就可，
模型参数提取还没来得及封装，下一步封装，现在手动提取，有点麻烦

